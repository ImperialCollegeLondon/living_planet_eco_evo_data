{"version":"1","records":[{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science"},"type":"lvl1","url":"/gis-practical","position":0},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science"},"content":"This webpage provides one long self-paced practical that provides an introduction to key\nspatial data handling and analysis techniques for use with the Ecological and\nEvolutionary Data Science. This practical uses \n\nthe R programming\nlanguage to load, manipulate and analyse spatial data. See\nmore here on \n\nwhy we use R for GIS.\n\nThere are a lot of other sites that provide information on using R for GIS:\n\nThe core textbook for this practical is \n\nGeocomputation with\nR - it forms part of a broader set of resources from the\n\n\ngeocompx group that provide resources for reproducible\ngeographic data analysis, modeling, and visualization in several open source\nlanguages, also including Python and Julia.\n\nAnother great resource is the \n\nrspatial website,\nwhich provides a lot of information on using terra and other spatial tools in R.","type":"content","url":"/gis-practical","position":1},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Aims of the the practical"},"type":"lvl2","url":"/gis-practical#aims-of-the-the-practical","position":2},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Aims of the the practical"},"content":"The practical aims to:\n\nProvide you with some high quality spatial datasets for the Silwood and NHM sites\nthat provide additional information that you can use to develop your hypotheses in\nyour coursework for the module.\n\nRun through most of the major GIS techniques that you will need to use to integrate\nraster and vector datasets in order to get to a final dataset addressing your\nhypotheses.\n\nProvide simple plotting options using the basic R graphics commands. For more\nadvanced mapping, see the \n\n“Making maps with R”\nchapter in “Geocomputation with R”.","type":"content","url":"/gis-practical#aims-of-the-the-practical","position":3},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"How to use the practical"},"type":"lvl2","url":"/gis-practical#how-to-use-the-practical","position":4},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"How to use the practical"},"content":"This practical is self-paced: work through it at your own speed and ask questions as\nneeded! It builds up and then saves a set of datasets that you can use in your\nassessment, so you will need to:\n\nFollow \n\nthis guide on setting up packages and data for\nthis practical.\n\nCreate a new R script file to run the practical analyses.\n\nCopy example code from the practical into your script and run it from your script.\n\nCheck you understand what the code is doing - add extra comments, ask questions.\n\nThe practical contains exercises where you are asked to use the previous example to\nwrite and run your own code. Write your solution into your script file and again add\ncomments for when you come back to it!\n\nThe practical contains solutions for all the exercises, but do try and solve them\nyourself.\n\nAt the end of the practical, you should have:\n\nA set of GIS data files that allow you to add further environmental context to the\noutputs of the sensor data exercises.\n\nA complete script that builds up those files from the original source data.","type":"content","url":"/gis-practical#how-to-use-the-practical","position":5},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Required packages"},"type":"lvl2","url":"/gis-practical#required-packages","position":6},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Required packages"},"content":"We will need to load the following packages:\n\nlibrary(terra)       # core raster GIS package\nlibrary(sf)          # core vector GIS package\nlibrary(rcartocolor) # plotting\nlibrary(rpart)\n\nYou will see a whole load of package loading messages about GDAL, GEOS, PROJ which are\nnot shown here. Don’t worry about this - they are not errors, just R linking to some key\nopen source GIS toolkits.","type":"content","url":"/gis-practical#required-packages","position":7},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Spatial datasets"},"type":"lvl2","url":"/gis-practical#spatial-datasets","position":8},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Spatial datasets"},"content":"We will be using a number of different datasets in both vector and raster format, at a\nrange of resolutions. They are not all in the same projection and so we will need to\nsupply coordinate system details. These can be very complex, but fortunately the \n\nEPSG\ndatabase now provides a set of consistent codes that can be use to\nspecify coordinate systems.\n\nWe will first load the location data from field datasets, which use GPS point location\ndata in the WGS84 projection (\n\nEPSG:4326) with units in degrees:\n\nThe sensor deployment locations (16 sites across both the NHM and Silwood).\n\nThe blue tit nest box sites at Silwood (222 sites) * The woodland survey data sites.\n\nWe will then load a set of additional data files in a wide range of formats. The\nfollowing datasets are all downloaded from the \n\nEdina\nDigimap system. This is a UK national GIS resource for\nhigher education, which you should be able to use for any UK based GIS whilst you are at\nthe college using your college credentials. All of these datasets use the the OSGB36 /\nBritish National Grid projected coordinate system\n(\n\nEPSG:27700), with units in metres.\n\nAerial photography: RGB raster data at 25cm resolution with a single 3 x 3 km pane each\nof the two sites.\n\nThe Ordnance Survey (OS) Terrain 5 digital elevation dataset: raster data at 5m\nresolution with 2 pairs of 5 x 5 km panes for each site.\n\nThe CEH LandCover Map 2024: a raster land cover classification map with a single 3 x 3\nkm pane for each site.\n\nThe OS VectorMap Local dataset: two 5 x 5 km panes of vector data for each site.\n\nThere are then two final datasets:\n\nSatellite data from the Sentinel 2 L2A product at a range of resolutions, using the\n\n\nUniversal Transverse Mercator\nsystem.\nThis projection uses multiple zones for different parts of the planet and the UK data\nis in UTM zone 30N (\n\nEPSG code EPSG:32630), with units of\nmeters.\n\nThe GPS route for Silwood Christmas (Silmas) fun run and walking route. This is again\nin WGS84 projection.\n\nThe sections below show how to load each dataset.","type":"content","url":"/gis-practical#spatial-datasets","position":9},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Sensor locations","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#sensor-locations","position":10},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Sensor locations","lvl2":"Spatial datasets"},"content":"The sensor stations at Silwood and the NHM are recorded as  a CSV file, providing\nstation data including the latitude and longitude of each site. This file is directly\ndownloaded from the Epicollect5 project. This is vector point data: precise locations\nfrom GPS associated with additional site data.\n\nThe data is first loaded as a simple CSV file.\n\nWe then need to convert the data to an sf (simple features) object. This is very\nlike a normal R data frame, but contains an additional geometry field that contains\nthe vector data geometries and the coordinate system. This is done using the\nsf::st_sf function to set the CSV fields that contain the point coordinates.\n\n# Load the data from the CSV file\nsensor_locations <- read.csv(\"../data/SensorSites/2025/sensor_sites_2025.csv\")\n\n# Convert to an sf object by setting the fields containing X and Y data and set \n# the projection of the dataset\nsensor_locations <- st_as_sf(\n  sensor_locations, \n  coords=c(\"long_Sensor_location\",\"lat_Sensor_location\"),\n  crs=\"EPSG:4326\"\n)\n\n","type":"content","url":"/gis-practical#sensor-locations","position":11},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Nest boxes","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#nest-boxes","position":12},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Nest boxes","lvl2":"Spatial datasets"},"content":"The locations of the Silwood blue tit nest boxes were also recorded using GPS. This is a\nlong-term dataset and these data have already been processed into specific GIS format:\nthe widely used \n\nshapefile format. The\nsf::st_read function is used to read existing GIS format files directly into an sf\nobject.\n\nnest_boxes <- st_read(\"../data/SpatialMethods/NestBoxes/NestBoxes.shp\")\n\nAs you can see from the output above, loading a GIS file using sf::stread produces\nquite a lot of information. This practical handout will generally hide that to keep the\npage size down. We can also look at what an sf object looks like if you print it out:\nvery like a dataframe with some extra header data.\n\nprint(head(nest_boxes))\n\nShapefile - not one file!\n\nConfusingly, a shapefile dataset is not a single file - a shapefile dataset consists\nof a set of related files with the same shared file name and a range of file type\nsuffixes (.shp, .dbf, .shx and .prj are the core subfiles but other suffixes are\ncommon). You must keep all of these files together, or the dataset will not load\ncorrectly.","type":"content","url":"/gis-practical#nest-boxes","position":13},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Woodland survey","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#woodland-survey","position":14},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Woodland survey","lvl2":"Spatial datasets"},"content":"The Silwood woodland survey transect points: another CSV file providing latitude and\nlongitude of transect locations.\n\nTODO","type":"content","url":"/gis-practical#woodland-survey","position":15},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Aerial photography","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#aerial-photography","position":16},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Aerial photography","lvl2":"Spatial datasets"},"content":"These raster datasets provide 3km by 3km panes of 25cm resolution \n\naerial photography\nimagery for the two sites. These files are provided\nas GeoTIFF data files - these are essentially just \n\nstandard TIFF\nimage files but contain metadata that provides the\nspatial context of each pixel in the image and the projection information.\n\nRaster data can be loaded using the terra::rast function.\n\nnhm_aerial <- rast('../data/SpatialMethods/aerial/nhm_aerial.tiff')\nsilwood_aerial <- rast('../data/SpatialMethods/aerial/silwood_aerial.tiff')\n\nPrinting out one of those fhiles shows the spatial information of the raster and then a\ntable showing the names of the bands in the raster and their range. These files contain\nthree band to provide RGB imagery.\n\nprint(nhm_aerial)\n\n","type":"content","url":"/gis-practical#aerial-photography","position":17},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"OS Terrain 5","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#os-terrain-5","position":18},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"OS Terrain 5","lvl2":"Spatial datasets"},"content":"These raster datasets provide continuous elevation data at 5m\nresolution from the \n\nOrdnance Survey Terrain 5 Digital Terrain Map (DTM)\ndataset. Each site has\ntwo adjoining panes of data.\n\nAside: coordinates in the British National Grid\n\nThe odd file names come from the British National Grid mapping system. The code SU96NE\nindicates the north east quadrant of a 10 x 10 km cell that is found 9 cells east and 6\ncells north within the 100 x 100 km SU cell. The SU cell itself is one of 25 cells\nwithin the 500 x 500 km S cell. You can add more digits to give more resolution. An 8\ndigit grid reference has a 10 metre precision: the Hamilton building is at SU 9469 6871 and the NHM Wildlife Garden is at TQ 2656 7899.\n\nSee \n\nhere for more details.\n\nThese files are ASC format files - a very simple text based format that contains the\ncell coordinates but not the projection metadata, so we need to add that information.\n\n# Load the DTM data from ASC format files\nsilwood_dtm_SU96NE <- rast(\"../data/SpatialMethods/dtm_5m/SU96NE.asc\")\nsilwood_dtm_SU96NW <- rast(\"../data/SpatialMethods/dtm_5m/SU96NW.asc\")\nnhm_dtm_TQ27NE <- rast(\"../data/SpatialMethods/dtm_5m/TQ27NE.asc\")\nnhm_dtm_TQ28SE <- rast(\"../data/SpatialMethods/dtm_5m/TQ28SE.asc\")\n\nIf we look at one of those datasets, you can see that the cell coordinates, resolution\nand overall dataset size have been set but that the coord. ref attribute is empty.\n\n# Look at the object data\nsilwood_dtm_SU96NE\n\nWe need to set the projection manually using the terra::crs function and then check\nthat the attribute has been set.\n\n# Set the projection information for the DTM datasets\ncrs(silwood_dtm_SU96NE) <- crs(silwood_dtm_SU96NW) <- \"EPSG:27700\"\ncrs(nhm_dtm_TQ27NE) <- crs(nhm_dtm_TQ28SE) <- \"EPSG:27700\"\n\n# Print the modified dataset\nsilwood_dtm_SU96NE\n\n","type":"content","url":"/gis-practical#os-terrain-5","position":19},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"CEH Land Cover","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#ceh-land-cover","position":20},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"CEH Land Cover","lvl2":"Spatial datasets"},"content":"The Centre for Ecology and Hydrology produces a UK wide land cover map at 10 metre\nresolution. The datasets here are taken from the most recent \n\nLand Cover Map\n2024.\n\nThe land cover categories are assigned using a classification of multi-band spectral\ndata from satellites onto the spectral signatures of known training sites. Each cell is\nassigned to the category with training signatures that most closely match the spectral\nsignature of the cell.\n\n# Load the land cover map datasets\nsilwood_LCM <- rast(\"../data/SpatialMethods/lcm_2024/Silwood_LCM2024.tiff\")\nnhm_LCM <- rast(\"../data/SpatialMethods/lcm_2024/NHM_LCM2024.tiff\")\n\n# Look at the raster details\nprint(silwood_LCM)\n\nThe LCM2024 files contain two raster bands. The first band is a numeric code\ngiving the land cover category. The second band give the probability of the cell having\nthat land cover type, based on the underlying classification. As loaded, these values\nare just numeric, so if we plot the data, we will get two continuous colour legends:\n\nplot(silwood_LCM)\n\nWe can add category labels and better category colours to make the data easier to use.\nThe labels and some colours are defined in a separate CSV file:\n\nlcm_info <- read.csv(\"../data/SpatialMethods/lcm_2024/LCM2024_info.csv\")\n\n# Set the band names, the category code labels and the colour tables\nlevels(nhm_LCM) <- lcm_info[c(\"value\", \"label\")]\ncoltab(nhm_LCM) <- lcm_info[c(\"value\", \"color\")]\nnames(nhm_LCM) <- c(\"LandCover\", \"Certainty\")\n\ncoltab(silwood_LCM) <- lcm_info[c(\"value\", \"color\")]\nlevels(silwood_LCM) <- lcm_info[c(\"value\", \"label\")]\nnames(silwood_LCM) <- c(\"LandCover\", \"Certainty\")\n\nNow we can now plot maps that have actual category labels:\n\npar(mfrow=c(1,2))\nplot(silwood_LCM[\"LandCover\"])\nplot(nhm_LCM[\"LandCover\"])\n\nAnd look at the frequencies of the different categories using the terra::freq function:\n\nnhm_freq <- freq(nhm_LCM[\"LandCover\"])\nsilwood_freq <- freq(silwood_LCM[\"LandCover\"])\n\n# Join the two datasets, including all categories\nmerge(\n  nhm_freq, silwood_freq, \n  by=\"value\", all=TRUE, suffixes = c(\".nhm\", \".silwood\")\n)\n\nWe can also use the data within raster layers with other non-spatial data exploration\ntechniques. For example, we can look at the distribution of cell certainties associated\nwith each category.\n\npar(mar = c(4, 12, 1, 1))\n\n# Plot cell assignment certainties as a function of land cover category\nboxplot(\n  silwood_LCM[\"Certainty\"], silwood_LCM[\"LandCover\"], \n  las = 1, ylab = \"\", horizontal=TRUE, main=\"Silwood\", xlab=\"Certainty\"\n)\nboxplot(\n  nhm_LCM[\"Certainty\"], nhm_LCM[\"LandCover\"], \n  las = 1, ylab = \"\", horizontal=TRUE, main=\"NHM\", xlab=\"Certainty\"\n)\n\n","type":"content","url":"/gis-practical#ceh-land-cover","position":21},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"OS VectorMap Local","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#os-vectormap-local","position":22},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"OS VectorMap Local","lvl2":"Spatial datasets"},"content":"The \n\nOrdnance Survey VectorMap\nLocal dataset provides\nvery high precision vector data on spatial features in the UK. These files are saved in\nthe \n\nGeoPackage file format (.gpkg). As\nwith the Terrain 5 data, the data from Edina Digimap consists of two 5 x 5 km panes for\neach site.\n\nA GeoPackage file can contain multiple vector datasets in a single file: these are\nusually called “layers” and so you will typically load one layer at a time. The code\nbelow uses the sf::st_layers command to show the available layers within one of the\nVML datasets.\n\nprint(st_layers(\"../data/SpatialMethods/VML/vml-su96ne.gpkg\"))\n\nWe can then use the sf::st_read function to read specific different layers for each\nsite.\n\n# Load the two panes of VML road centrelines for each site.\nvml_tq28se_roads <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-tq28se.gpkg\", layer = \"Road_Centreline\"\n)\nvml_tq27ne_roads <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-tq27ne.gpkg\", layer = \"Road_Centreline\"\n)\nvml_su96ne_roads <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-su96ne.gpkg\", layer = \"Road_Centreline\"\n)\nvml_su96nw_roads <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-su96nw.gpkg\", layer = \"Road_Centreline\"\n)\n\n# Do the same for water bodies\nvml_tq28se_water <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-tq28se.gpkg\", layer = \"Water_Area\"\n)\nvml_tq27ne_water <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-tq27ne.gpkg\", layer = \"Water_Area\"\n)\nvml_su96ne_water <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-su96ne.gpkg\", layer = \"Water_Area\"\n)\nvml_su96nw_water <- st_read(\n  dsn = \"../data/SpatialMethods/VML/vml-su96nw.gpkg\", layer = \"Water_Area\"\n)\n\n","type":"content","url":"/gis-practical#os-vectormap-local","position":23},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Sentinel 2 data","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#sentinel-2-data","position":24},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Sentinel 2 data","lvl2":"Spatial datasets"},"content":"The Sentinel 2 satellite mission collects spectral data from \n\n13\nbands across the visible,\nnear infra-red and infra-red at resolutions from 10m to 60m. See the \n\nCopernicus\nSentinel 2 data wiki for more\ninformation about the mission and data processing.\n\nThe sentinel_2 folder contains data from a single (relatively cloud free!) scene from\nthe \n\nSentinel 2 Level 2A data\nproduct\nthat was downloaded using the \n\nCopernicus data\nbrowser. The L2A data product has been\nprocessed to remove atmospheric effects to give modelled surface reflectance values for\neach band and also to add some extra calculated layers, such as true colour images (more\non this later!).\n\nA single scene of L2A data covers roughly 110 x 110 km and contains about 1 GB of data,\nso has been cropped down to the two study sites (see \n\nbelow). The\ncode below loads the four 10m resolution bands into a single raster for each site by\nproviding a vector of file names to the terra::rast function. It also rescales the\ndata: remote sensing data is often stored as integer data to save file space and needs\nconverting to actual values, in this case by dividing by 10000.\n\n# Load the four 10m resolution Sentinel 2 bands for Silwood\ns2_silwood_10m <- rast(\n    c(\n        \"../data/SpatialMethods/sentinel_2/R10m/silwood/T30UXC_20250711T110651_B02_10m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R10m/silwood/T30UXC_20250711T110651_B03_10m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R10m/silwood/T30UXC_20250711T110651_B04_10m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R10m/silwood/T30UXC_20250711T110651_B08_10m.tiff\"\n    ),\n)  / 10000\n\n# Name the bands \nnames(s2_silwood_10m) <- c(\"B\", \"G\", \"R\", \"NIR\")\n\n# Do the same for the NHM\ns2_nhm_10m <- rast(\n    c(\n        \"../data/SpatialMethods/sentinel_2/R10m/nhm/T30UXC_20250711T110651_B02_10m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R10m/nhm/T30UXC_20250711T110651_B03_10m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R10m/nhm/T30UXC_20250711T110651_B04_10m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R10m/nhm/T30UXC_20250711T110651_B08_10m.tiff\"\n    ),\n) / 10000\nnames(s2_nhm_10m) <- c(\"B\", \"G\", \"R\", \"NIR\")\n\n# Show the resulting object structure\nprint(s2_silwood_10m)\n\nExercise\n\nThe Sentinel 2 dataset directory also includes the band data sampled at 20m and 60m\nresolution. The 60m bands are largely aimed at detecting water vapour and clouds, but\nthe 20 metre bands include red edge, narrow near infrared and short wave infrared data\nthat can be useful. Use the code above as a template to load Bands 5, 6, 7, 8A, 11 and\n12 from the 20 meter directories for each site. Note that the 20m directory also\ncontains downsampled data from the 10 metre bands.\n\nThe resulting objects should be called s2_silwood_20m and s2_nhm_20m and the bands\nshould be named RE5, RE6, RE7, NNIR, SWIR1 and SWIR2.\n\nShow solution\n\n# Load the six 20m resolution Sentinel 2 bands for Silwood\ns2_silwood_20m <- rast(\n    c(\n        \"../data/SpatialMethods/sentinel_2/R20m/silwood/T30UXC_20250711T110651_B05_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/silwood/T30UXC_20250711T110651_B06_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/silwood/T30UXC_20250711T110651_B07_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/silwood/T30UXC_20250711T110651_B8A_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/silwood/T30UXC_20250711T110651_B11_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/silwood/T30UXC_20250711T110651_B12_20m.tiff\"\n    ),\n) / 10000\n\n# Name the bands \nnames(s2_silwood_20m) <- c(\"RE5\", \"RE6\", \"RE7\", \"NNIR\", \"SWIR1\", \"SWIR2\")\n\n# Load the seven 20m resolution Sentinel 2 bands for the NHM\ns2_nhm_20m <- rast(\n    c(\n        \"../data/SpatialMethods/sentinel_2/R20m/nhm/T30UXC_20250711T110651_B05_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/nhm/T30UXC_20250711T110651_B06_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/nhm/T30UXC_20250711T110651_B07_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/nhm/T30UXC_20250711T110651_B8A_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/nhm/T30UXC_20250711T110651_B11_20m.tiff\",\n        \"../data/SpatialMethods/sentinel_2/R20m/nhm/T30UXC_20250711T110651_B12_20m.tiff\"\n    ),\n) / 10000\n\n# Name the bands \nnames(s2_nhm_20m) <- c(\"RE5\", \"RE6\", \"RE7\", \"NNIR\", \"SWIR1\", \"SWIR2\")","type":"content","url":"/gis-practical#sentinel-2-data","position":25},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Silmas walk/run route","lvl2":"Spatial datasets"},"type":"lvl3","url":"/gis-practical#silmas-walk-run-route","position":26},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Silmas walk/run route","lvl2":"Spatial datasets"},"content":"The last dataset is a \n\nGPS Exchange Format (GPX)\nfile containing the course of the\nSilmas fun run and walking route. The GPX format is a commonly used format to record\nroutes and points from GPS devices. Again, the format holds multiple layers:\n\nprint(st_layers(\"../data/SpatialMethods/Silmas_Fun_Run.gpx\"))\n\nWith GPX files, there are a fixed number of layers. They are not all used in this file:\nwe have a single linear feature in tracks layer, which is the Silmas route, and then\nthe 425 point features in the track_points layer, which are the points along\nalong that route. We will load the  tracks layer:\n\nsilmas_route <- st_read(\n  dsn=\"../data/SpatialMethods/Silmas_Fun_Run.gpx\", layer=\"tracks\"\n)\n\n","type":"content","url":"/gis-practical#silmas-walk-run-route","position":27},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Plotting GIS data"},"type":"lvl2","url":"/gis-practical#plotting-gis-data","position":28},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Plotting GIS data"},"content":"Hint\n\nThese are very basic plotting tips for GIS data, but are all we need for this\npractical.","type":"content","url":"/gis-practical#plotting-gis-data","position":29},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Plotting vector data","lvl2":"Plotting GIS data"},"type":"lvl3","url":"/gis-practical#plotting-vector-data","position":30},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Plotting vector data","lvl2":"Plotting GIS data"},"content":"If you plot a vector dataset, then it will generate a panel for each vector attribute in\nthe dataset (up to a limit!).\n\nplot(nest_boxes)\n\nIf you want to plot just one of those attributes, then you can use [] subsets to do\nso, and R will generate a key for it.\n\nplot(nest_boxes['SPlocation'], key.pos=4)\n\nIf you just want to plot the features geometry, then you can use sf::st_geometry. You\ncan use add=TRUE to overplot features and you can use extent to change the spatial\narea being plotted. It can be tricky to set the area of the plot so that it will include\nall features. One trick here is to get the extent (or bounding box) of the layers you\nwant to plot and then convert them to polygons using sf::st_as_sfc and then take the\nspatial union(sf::st_union) of those boxes. Long-winded but reliable!\n\n# Get the plot extent as the union of the bounding boxes\nplot_extent <- st_union(\n  st_as_sfc(st_bbox(nest_boxes)),\n  st_as_sfc(st_bbox(silmas_route))\n)\n\n# Plot the nest box points and overplot the Silmas route\nplot(st_geometry(nest_boxes), col=\"forestgreen\", extent=plot_extent)\nplot(st_geometry(silmas_route), col=\"red\", add=TRUE)\n\n","type":"content","url":"/gis-practical#plotting-vector-data","position":31},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Plotting raster data","lvl2":"Plotting GIS data"},"type":"lvl3","url":"/gis-practical#plotting-raster-data","position":32},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Plotting raster data","lvl2":"Plotting GIS data"},"content":"If you plot a raster object, it will plot each band separately:\n\n# Plot the 3 bands of the silwood aerial image\nnames(silwood_aerial) <- c(\"Red\", \"Green\", \"Blue\")\nplot(silwood_aerial, nc=3)\n\nIf you instead want to combine image bands to create a three colour image, then the\nterra::plotRGB  can be used to combine 3 bands to generate a colour composite image.\nThe silwood_aerial image contains the three RGB bands in the correct order, so we can\nsimply plot it:\n\n# Plot the silwood aerial data using the default settings\nplotRGB(silwood_aerial)\n\nIf we want to do the same thing with the RGB data from the Sentinel 2 data then we need\nto adjust the command to give the bands in the right order and also to set the maximum\nscale of the values across the bands.\n\n# Plot the Sentinel data, setting the bands and scale\nplotRGB(s2_silwood_10m, r=3, g=2, b=1, scale=0.80)\n\nIn fact, the L2A Sentinel 2 product provides a True Colour Image (TCI) that orders and\nscale the RGB bands to give something closer to expected colour. This can be used with\nthe default settings.\n\n# Load the L2A TCI image for Silwood and plot using defaults.\ns2_silwood_tci <- rast(\n  \"../data/SpatialMethods/sentinel_2/R10m/silwood/T30UXC_20250711T110651_TCI_10m.tiff\"\n)\nplotRGB(s2_silwood_tci)\n\nAlternatively, you can set different bands as inputs to give a “false-colour image”. One\ncommon usage is a \n\nfalse colour\ninfrared\nimage, which swaps from the [R, G, B] bands to [NIR, R, G]. This kind of imagery is\nvery good at pulling out differences between vegetation (bright red), water (dark) and\nurban areas and bare ground (tan or grey).\n\n# Plot the Sentinel data, setting the bands and scale\nplotRGB(s2_silwood_10m, r=4, g=3, b=2, scale=0.8)\n\n \nNOTE - there are no changes to the data objects in this document so there is no \ncode cell required to save changes to the data state.\n","type":"content","url":"/gis-practical#plotting-raster-data","position":33},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Reprojecting spatial data"},"type":"lvl2","url":"/gis-practical#reprojecting-spatial-data","position":34},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Reprojecting spatial data"},"content":"We now have a large number of different datasets, but they are not all in the same GIS\nprojection. We cannot use the datasets together until they use the same coordinate\nsystem. We will use the “OSGB 1936 / British National Grid” (or BNG) projection for all\nof the rest of the practical. It is a projected coordinate system, which means we can\nuse metres to measure distances, and it is also the standard mapping system for the UK.","type":"content","url":"/gis-practical#reprojecting-spatial-data","position":35},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Reprojecting vector datasets","lvl2":"Reprojecting spatial data"},"type":"lvl3","url":"/gis-practical#reprojecting-vector-datasets","position":36},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Reprojecting vector datasets","lvl2":"Reprojecting spatial data"},"content":"It is relatively easy to reproject vector datasets: all of the features in a vector\ndataset are built up from pairs of point. Reprojection is therefore just a matter of\nrecalculating the coordinates in the new projection - the underlying equation might be\ncomplex but we are just moving points between two systems.\n\nWe can show the current range of coordinates for a dataset by looking at the extent\nof the data before.\n\n# Show the extent of the sensor locations in the current WGS84 projection\next(sensor_locations)\n\nThe sf::st_transform function can then be used to transform data from one projection\nto another.\n\n# Convert the WGS84 vector datasets to BNG\nsensor_locations <- st_transform(sensor_locations, crs=\"EPSG:27700\")\nnest_boxes <- st_transform(nest_boxes, crs=\"EPSG:27700\")\nsilmas_route <- st_transform(silmas_route, crs=\"EPSG:27700\")\n\n# Show the new extent\next(sensor_locations)\n\n","type":"content","url":"/gis-practical#reprojecting-vector-datasets","position":37},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Reprojecting raster datasets","lvl2":"Reprojecting spatial data"},"type":"lvl3","url":"/gis-practical#reprojecting-raster-datasets","position":38},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Reprojecting raster datasets","lvl2":"Reprojecting spatial data"},"content":"This is more involved than reprojecting vector data. You have a series of raster cell\nvalues in one projection and then want to insert representative values into a set of\ncells on a different projection. The borders of those new cells could have all sorts of\nodd relationships to the current ones.\n\nWe can show the issue by superimposing two grids:\n\nA 200 m resolution grid using the extent of the BNG projection datasets for Silwood\n(red cells).\n\nA very similar 200m grid taken from the extent of the Sentinel 2 data in the UTM30N\nprojection for the same site and then reprojected into the BNG (grey cells)\n\n# Create a BNG raster at 200m resolution for the study site\ngrid_BNG <- rast(ext(silwood_aerial), res = 200, crs = \"EPSG:27700\")\n# Convert to an sf polygon dataset of grid cells\ngrid_BNG <- st_as_sf(as.polygons(grid_BNG))\n\n# Create a UTM30N raster at 200 m resolution for the study site\ngrid_UTM30N <- rast(ext(s2_silwood_10m), res = 200, crs = \"EPSG:32630\")\n# Convert to an sf polygon dataset _and_ then transform to BNG\ngrid_UTM30N <- st_as_sf(as.polygons(grid_UTM30N))\ngrid_UTM30N_in_BNG <- st_transform(grid_UTM30N, \"EPSG:27700\")\n\n# Plot the two sets of grid cells over each other\nplot(st_geometry(grid_UTM30N_in_BNG), reset=FALSE, border=\"grey\")\nplot(st_geometry(grid_BNG), border='red', add=TRUE)\n\n# Add coordinates on the axes\naxis(1)\naxis(2)\n\nPlot source\n\nIn case you are interested in how the plot was created.# Create a BNG raster at 200m resolution for the study site\ngrid_BNG <- rast(ext(silwood_aerial), res = 200, crs = \"EPSG:27700\")\n# Convert to an sf polygon dataset of grid cells\ngrid_BNG <- st_as_sf(as.polygons(grid_BNG))\n\n# Create a UTM30N raster at 200 m resolution for the study site\ngrid_UTM30N <- rast(ext(s2_silwood_10m), res = 200, crs = \"EPSG:32630\")\n# Convert to an sf polygon dataset _and_ then transform to BNG\ngrid_UTM30N <- st_as_sf(as.polygons(grid_UTM30N))\ngrid_UTM30N_in_BNG <- st_transform(grid_UTM30N, \"EPSG:27700\")\n\n# Plot the two sets of grid cells over each other\nplot(st_geometry(grid_UTM30N_in_BNG), reset=FALSE, border=\"grey\")\nplot(st_geometry(grid_BNG), border='red', add=TRUE)\n\n# Add coordinates on the axes\naxis(1)\naxis(2)\n\nAs you can see, even when the resolutions are the same, there is no neat one-to-one\nrelationship between the two sets of cells: the axes of the two grids are not exactly\nparallel and the coordinates of the cell boundaries are not the same.\n\nThe terra::project function both converts the coordinates from one projection to\nanother and resamples the data from one grid to another. There are various methods\nto carry out resampling - see the method details in ?project but they basically fall\ninto two groups:\n\nMost are interpolations methods for getting a representative continuous value for\neach cell from the data in the original raster grid. They range from simple average\nvalues of intersecting cells, to more complex polynomials and splines (e.g cubic)\nthat use a moving window of a neighbourhood of cells to construct an estimate for the\nnew cell.\n\nOther approaches select a single value from the source grid: the near method takes\nthe value from the source raster cell closest to the centre of the new cell, and the\nmode value takes the modal value of the set of overlapping cells. Both of these\napproaches are intended for use with categorical raster data, where it makes no sense\nto interpolate values between category codes.\n\nTo use the terra::project function, you need to provide a raster with the target\nresolution and projection to use as a template. To reproject the Sentinel 2 data, we can\nsimply use the Land Cover map datasets, which are also have a 10m resolution and have\nbeen cropped to the study area.\n\ns2_silwood_10m <- project(s2_silwood_10m, silwood_LCM, method=\"cubic\")\ns2_nhm_10m <- project(s2_nhm_10m, nhm_LCM, method=\"cubic\")\n\nExercise\n\nRepeat this reprojection for the 20 metre resolution Sentinel 2 datasets that you\ncreated earlier (s2_silwood_20m and s2_nhm_20m).\n\nYou should reproject the data to the same 20 metre resolution. We do not have an\nexisting BNG raster dataset at this resolution, so you will need to make one.\n\nShow solution\n\n# Make 20 metre resolution templates for the study sites\nsilwood_template_20m <- rast(ext(silwood_aerial), res=20, crs=\"EPSG:27700\")\nnhm_template_20m <- rast(ext(nhm_aerial), res=20, crs=\"EPSG:27700\")\n\n# Reproject S2 20m bands into BNG\ns2_silwood_20m <- project(s2_silwood_20m, silwood_template_20m, method=\"cubic\")\ns2_nhm_20m <- project(s2_nhm_20m, nhm_template_20m, method=\"cubic\")","type":"content","url":"/gis-practical#reprojecting-raster-datasets","position":39},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Manipulating raster data"},"type":"lvl2","url":"/gis-practical#manipulating-raster-data","position":40},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Manipulating raster data"},"content":"Even once you have raster datasets in the same resolution, it is common to want to\nmanipulate them to get multiple datasets into the same extent and resolution. This\nsection covers:\n\nupscaling and downscaling raster resolution,\n\njoining adjacent raster tiles into a single dataset,\n\ncombining raster bands for datasets with the same extent and resolution, and\n\ncropping datasets to a smaller extent.","type":"content","url":"/gis-practical#manipulating-raster-data","position":41},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Changing raster resolution","lvl2":"Manipulating raster data"},"type":"lvl3","url":"/gis-practical#changing-raster-resolution","position":42},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Changing raster resolution","lvl2":"Manipulating raster data"},"content":"If you want to change the resolution or grid of an existing raster grid without\nchanging the projection then you there are a few options:\n\nIf you want to change the grid resolution by a simple factor while keeping the same\nbasic grid cell alignments and extent, then you can use the terra::aggregate and\nterra::disagg functions.\n\nIf you need to change the grid to a raster resolution that is not a simple factor or\nneed to move the cell boundaries to match another dataset, then you will need the\nterra::resample function. This functions much like terra::project without the\ncoordinate transformation, and has the same methods for resampling onto the new grid.\n\nHere, we will use disaggregation to resample the 20 metre resolution Sentinel 2 bands to\n10 metre resolution. We will use method=bilinear which uses a simple linear model to\nassign new cell values; the alternative method=near would simply duplicate the value\nfrom the nearest coarser resolution cell into each of the smaller cells.\n\ns2_silwood_20m_at_10m <- disagg(s2_silwood_20m, fact=2, method=\"bilinear\")\ns2_nhm_20m_at_10m <- disagg(s2_nhm_20m, fact=2, method=\"bilinear\")\n\nWe can use the terra::res function to show the resolutions of the two versions.\n\nprint(res(s2_silwood_20m))\nprint(res(s2_silwood_20m_at_10m))\n\nStretch goal: projecting Sentinel 2 to 10m resolution\n\nWe could also have got the 20 metre resolution Sentinel 2 bands resampled to 10 metres\nusing  only the terra::project function. See if you can generate\ns2_silwood_20m_direct_to_10m and s2_nhm_20m_direct_to_10m using only that function.\n\nShow solution\n\n# It is actually very easy - we can just use the existing 10m CEH Land Cover Map\n# datasets as the resampling template.\ns2_silwood_20m_direct_to_10m <- project(\n  s2_silwood_20m, silwood_lcm, method=\"cubic\"\n)\ns2_nhm_20m_direct_to_10m <- project(\n  s2_nhm_20m, nhm_lcm, method=\"cubic\"\n)","type":"content","url":"/gis-practical#changing-raster-resolution","position":43},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Mosaicing rasters","lvl2":"Manipulating raster data"},"type":"lvl3","url":"/gis-practical#mosaicing-rasters","position":44},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Mosaicing rasters","lvl2":"Manipulating raster data"},"content":"We can mosaic the two panes of Terrain 5 data for each site from two 5km panes into\na single rectangle of data. The two panes are side by side for Silwood and one above the\nother for the NHM. The plot below shows the 5 x 5 km extent of the two panes. The figure\nalso shows the 3 x 3 km extent of the other data sources - as you can see it overlaps\nthe Terrain 5 panes for both sites, which is why we needed to load two panes.\n\noptions(repr.plot.height=4)\n\npar(mfrow=c(1,2))\n\n# Calculate the union of the extents of the two rasters\nsilwood_dtm_extent <- union(ext(silwood_dtm_SU96NE), ext(silwood_dtm_SU96NW ))\n\n# Plot the extent of the first raster, but using the extent of both datasets\nplot(ext(silwood_dtm_SU96NE), border=\"blue\", ext=silwood_dtm_extent, main=\"Silwood\")\n\n# Get the middle coordinates of the raster and add a label. The `xFromCol` and \n# `yFromRow` functions extract the X and Y coordinates of cell centres from the \n# raster and `mean` then gives the centre of the raster image.\ntext(\n  x=mean(xFromCol(silwood_dtm_SU96NE)), \n  y=mean(yFromRow(silwood_dtm_SU96NE)),\n  labels=\"SU96NE\", col=\"blue\"\n)\n\n# Use `add=TRUE` to add the extent of the second raster and add the label\nplot(ext(silwood_dtm_SU96NW), border=\"red\", add=TRUE)\ntext(\n  x=mean(xFromCol(silwood_dtm_SU96NW)), \n  y=mean(yFromRow(silwood_dtm_SU96NW)),\n  labels=\"SU96NW\", col=\"red\"\n)\n\n# Finally add the extent of the other raster datasets \nplot(ext(silwood_aerial), border=\"black\", add=TRUE)\n\n# Repeat for the NHM datasets\nnhm_dtm_extent <- union(ext(nhm_dtm_TQ27NE), ext(nhm_dtm_TQ28SE))\n\nplot(ext(nhm_dtm_TQ27NE), border=\"blue\", ext=nhm_dtm_extent, main=\"NHM\")\ntext(\n  x=mean(xFromCol(nhm_dtm_TQ27NE)), \n  y=mean(yFromRow(nhm_dtm_TQ27NE)),\n  labels=\"TQ27NE\", col=\"blue\"\n)\nplot(ext(nhm_dtm_TQ28SE), border=\"red\", add=TRUE)\ntext(\n  x=mean(xFromCol(nhm_dtm_TQ28SE)), \n  y=mean(yFromRow(nhm_dtm_TQ28SE)),\n  labels=\"TQ28SE\", col=\"red\"\n)\nplot(ext(nhm_aerial), border=\"black\", add=TRUE)\n\nShow source code for plot\n\nThe plot above uses a few useful plotting tricks for spatial data:\n\nchanging the spatial extent of the plot to include more than one dataset,\n\nadding mutiple layers to a spatial plot, and\n\nusing coordinates to add text.\n\nYou do not need to know these details for the practical, but this might be something to\ncome back to and look at.options(repr.plot.height=4)\n\npar(mfrow=c(1,2))\n\n# Calculate the union of the extents of the two rasters\nsilwood_dtm_extent <- union(ext(silwood_dtm_SU96NE), ext(silwood_dtm_SU96NW ))\n\n# Plot the extent of the first raster, but using the extent of both datasets\nplot(ext(silwood_dtm_SU96NE), border=\"blue\", ext=silwood_dtm_extent, main=\"Silwood\")\n\n# Get the middle coordinates of the raster and add a label. The `xFromCol` and \n# `yFromRow` functions extract the X and Y coordinates of cell centres from the \n# raster and `mean` then gives the centre of the raster image.\ntext(\n  x=mean(xFromCol(silwood_dtm_SU96NE)), \n  y=mean(yFromRow(silwood_dtm_SU96NE)),\n  labels=\"SU96NE\", col=\"blue\"\n)\n\n# Use `add=TRUE` to add the extent of the second raster and add the label\nplot(ext(silwood_dtm_SU96NW), border=\"red\", add=TRUE)\ntext(\n  x=mean(xFromCol(silwood_dtm_SU96NW)), \n  y=mean(yFromRow(silwood_dtm_SU96NW)),\n  labels=\"SU96NW\", col=\"red\"\n)\n\n# Finally add the extent of the other raster datasets \nplot(ext(silwood_aerial), border=\"black\", add=TRUE)\n\n# Repeat for the NHM datasets\nnhm_dtm_extent <- union(ext(nhm_dtm_TQ27NE), ext(nhm_dtm_TQ28SE))\n\nplot(ext(nhm_dtm_TQ27NE), border=\"blue\", ext=nhm_dtm_extent, main=\"NHM\")\ntext(\n  x=mean(xFromCol(nhm_dtm_TQ27NE)), \n  y=mean(yFromRow(nhm_dtm_TQ27NE)),\n  labels=\"TQ27NE\", col=\"blue\"\n)\nplot(ext(nhm_dtm_TQ28SE), border=\"red\", add=TRUE)\ntext(\n  x=mean(xFromCol(nhm_dtm_TQ28SE)), \n  y=mean(yFromRow(nhm_dtm_TQ28SE)),\n  labels=\"TQ28SE\", col=\"red\"\n)\nplot(ext(nhm_aerial), border=\"black\", add=TRUE)\n\nWe use the terra::mosaic function to combine these two panes into a single dataset for\neach site. There is also the terra::merge function: this is used to combine aligned\nraster datasets that are not simply neatly adjoining tiles. It also make life easier if\nwe update these datasets so they use the same raster layer name - they currently are\nnamed by BNG grid pane.\n\n# Mosaic the two Terrain 5 panes into a single dataset\nsilwood_dtm <- mosaic(silwood_dtm_SU96NE, silwood_dtm_SU96NW)\nnhm_dtm <- mosaic(nhm_dtm_TQ27NE, nhm_dtm_TQ28SE)\n\n# Update the raster layer names\nnames(silwood_dtm) <- names(nhm_dtm) <- \"Elevation\"\n\nWe can check the extents to show what happened - the new Silwood terrain dataset now has\na 10km extent in the X dimension.\n\nprint(ext(silwood_dtm_SU96NE))\nprint(ext(silwood_dtm_SU96NW))\nprint(ext(silwood_dtm))\n\n","type":"content","url":"/gis-practical#mosaicing-rasters","position":45},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Combining raster bands","lvl2":"Manipulating raster data"},"type":"lvl3","url":"/gis-practical#combining-raster-bands","position":46},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Combining raster bands","lvl2":"Manipulating raster data"},"content":"We can also combine rasters with the same resolution and grid to add more bands onto an\nexisting dataset. We can do this to create a new Sentinel 2 dataset that includes the\noriginal 10 metre resolution bands and the 20 metre bands that we resampled to 10\nmetres. The terra package takes the standard c() function for combining R vectors\nand lists and extends that to join raster layers by band.\n\n# Combine the S2 10m bands with the resampled 20 m bands.\ns2_silwood_10m <- c(s2_silwood_10m, s2_silwood_20m_at_10m)\ns2_nhm_10m <- c(s2_nhm_10m, s2_nhm_20m_at_10m)\n\n","type":"content","url":"/gis-practical#combining-raster-bands","position":47},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Cropping rasters","lvl2":"Manipulating raster data"},"type":"lvl3","url":"/gis-practical#cropping-rasters","position":48},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Cropping rasters","lvl2":"Manipulating raster data"},"content":"You can reduce the size of a raster dataset to a particular area of interest using the\nterra::crop function. We will use this to extract the 3km area of interest from the\nnewly mosaiced datasets. All we need to provide is another dataset that has the required\nextent.\n\n# Crop the mosaiced DTM data to the 3km area of interest.\nsilwood_dtm <- crop(silwood_dtm, silwood_aerial)\nnhm_dtm <- crop(nhm_dtm, nhm_aerial)\n\nWe can again check the extents of the resulting grids to check that they match:\n\n# Crop the mosaiced DTM data to the 3km area of interest.\nprint(ext(silwood_dtm))\nprint(ext(silwood_aerial))\n\n","type":"content","url":"/gis-practical#cropping-rasters","position":49},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Manipulating vector data"},"type":"lvl2","url":"/gis-practical#manipulating-vector-data","position":50},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Manipulating vector data"},"content":"Vector data manipulation is generally either to merge two datasets or to crop data to a\nsmaller spatial extent.","type":"content","url":"/gis-practical#manipulating-vector-data","position":51},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Merging vector data","lvl2":"Manipulating vector data"},"type":"lvl3","url":"/gis-practical#merging-vector-data","position":52},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Merging vector data","lvl2":"Manipulating vector data"},"content":"Vector data is easier to merge in some ways: because the coordinates are recorded\nas sets of point forming features, you don’t have to worry about cell alignment or\nresolution. However, to merge a set of spatial features:\n\nThe two datasets have to have the same attributes: the data associated with each\nfeature needs to match.\n\nThe two datasets have to be in the same projection.\n\nProvided these two things are true, then merging two vector datasets is basically the\nsame as binding together the rows of two data frames with the same structure. The sf\npackage provides a version of the rbind function that joins two sf objects, and we\ncan use this to combine the two VML panes for the sites.\n\n# Combine the road panes\nsilwood_VML_roads <- rbind(vml_su96ne_roads, vml_su96nw_roads)\nnhm_VML_roads <- rbind(vml_tq28se_roads, vml_tq27ne_roads)\n\n# Combine the water area panes\nsilwood_VML_water <- rbind(vml_su96ne_water, vml_su96nw_water)\nnhm_VML_water <- rbind(vml_tq28se_water, vml_tq27ne_water)\n\nIf we plot the extents of the new combined data (grey) and the source panes (red and\nblue) for Silwood, you can see that the panes are not neatly aligned with actual BNG\ngrid cell bounds used by the elevation data (dashed panes). Raster cells by definition\nfall onto a neat grid, but vector features cross boundaries and it is common for\ndatasets to include features that fall outside the strict pane boundaries.\n\n# Merged data\nplot(st_as_sfc(st_bbox(silwood_VML_roads)), border='grey', lwd=4)\n\n# SU96NW panes of vector (solid) and raster (dashed) data\nplot(st_as_sfc(st_bbox(vml_su96nw_roads)), border='blue', add=TRUE)\nplot(st_as_sfc(st_bbox(silwood_dtm_SU96NW)), border='blue', add=TRUE, lty=2)\n\n# SU96NE panes of vector (solid) and raster (dashed) data\nplot(st_as_sfc(st_bbox(vml_su96ne_roads)), border='red', add=TRUE)\nplot(st_as_sfc(st_bbox(silwood_dtm_SU96NE)), border='red', add=TRUE, lty=2)\n\n","type":"content","url":"/gis-practical#merging-vector-data","position":53},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Cropping vector data","lvl2":"Manipulating vector data"},"type":"lvl3","url":"/gis-practical#cropping-vector-data","position":54},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Cropping vector data","lvl2":"Manipulating vector data"},"content":"We can crop the VML data down to the study site using the sf::st_crop function. It is\nusually faster and easier to reduce datasets to only the focal area you are working\nwith.\n\n# Crop the two vector datasets\nsilwood_VML_roads <- st_crop(silwood_VML_roads, silwood_aerial)\nnhm_VML_roads <- st_crop(nhm_VML_roads, nhm_aerial)\nsilwood_VML_water <- st_crop(silwood_VML_water, silwood_aerial)\nnhm_VML_water <- st_crop(nhm_VML_water, nhm_aerial)\n\nWe can now create a simple plot overlaying the vector roads and water over the top of\nthe digital elevations maps, again using sf::st_geometry to just show the geometries\nof the vector features.\n\npar(mfrow=c(1, 2))\n\nplot(silwood_dtm, col=grey.colors(20), main=\"Silwood\")\nplot(st_geometry(silwood_VML_roads), col=\"firebrick\", add = TRUE)\nplot(st_geometry(silwood_VML_water), col=\"cornflowerblue\", border=NA, add = TRUE)\n\nplot(nhm_dtm, col=grey.colors(20), main=\"NHM\")\nplot(st_geometry(nhm_VML_roads), col=\"firebrick\", add = TRUE)\nplot(st_geometry(nhm_VML_water), col=\"cornflowerblue\", border=NA, add = TRUE)\n\n \n\n### Vector operations\n\nwithin, voronoi etc?\n\n```{code-cell} r\nwithin_25 <- st_within(nest_boxes, nest_boxes_25, sparse=FALSE)\nn_within_25 <- colSums(within_25)\n```\n ","type":"content","url":"/gis-practical#cropping-vector-data","position":55},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Raster calculations"},"type":"lvl2","url":"/gis-practical#raster-calculations","position":56},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Raster calculations"},"content":"A layer in a continuous raster dataset is basically just a large numeric matrix. This\nmeans you can use raster layers in equations to calulate new composite indices that\nemphasize different parts of the spectral signal. There are a very large number of\nremote sensing indices and the \n\nSentinel-Hub scripts\nsite\nprovides formulae for a wide range of options. Here we will look at two simple\nvegetation indices.","type":"content","url":"/gis-practical#raster-calculations","position":57},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"NDVI","lvl2":"Raster calculations"},"type":"lvl3","url":"/gis-practical#ndvi","position":58},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"NDVI","lvl2":"Raster calculations"},"content":"The normalised difference vegetation index (NDVI) is defined as:NDVI = \\frac{\\text{NIR} - \\text{RED}}{\\text{NIR} + \\text{RED}}\n\nwhere NIR is band data for the near infrared and RED is band data in the red spectrum,\nwhich are Sentinel 2 bands B8 and B4. The index returns values from -1 (water) through 0\n(rock and bare ground) to 1 (rainforest). See \n\nthe Sentinel-Hub NDVI script page for\nmore details.\n\n# Calculate the NDVI index for the two sites\nndvi_nhm <- (\n  s2_nhm_10m[[\"NIR\"]] - s2_nhm_10m[[\"R\"]]) / \n  (s2_nhm_10m[[\"NIR\"]] + s2_nhm_10m[[\"R\"]]\n)\nndvi_silwood <- (\n  s2_silwood_10m[[\"NIR\"]] - s2_silwood_10m[[\"R\"]]) / \n  (s2_silwood_10m[[\"NIR\"]] + s2_silwood_10m[[\"R\"]]\n)\n# Rename the single band \nnames(ndvi_silwood) <- names(ndvi_nhm) <- \"NDVI\"\n\n# Plot the NDVI index data\npar(mfrow=c(1, 2))\nplot(ndvi_silwood)\nplot(ndvi_nhm)\n\n","type":"content","url":"/gis-practical#ndvi","position":59},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"EVI","lvl2":"Raster calculations"},"type":"lvl3","url":"/gis-practical#evi","position":60},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"EVI","lvl2":"Raster calculations"},"content":"The enhanced vegetation index (EVI) is very similar but includes scaling factors and\nuses the Blue band (Sentinel B2) to improve how well the index captures vegetation. The\nscale again extends from -1 to 1. See \n\nthe Sentinel-Hub EVI script page for\nmore details.EVI = 2.5 \\cdot \\left( \\frac{\\text{NIR} - \\text{RED}}\n  {\\text{NIR} + 6 \\cdot \\text{RED} - 7.5 \\cdot \\text{BLUE} + 1} \\right)\n\n# Calculate the EVI index for the two sites\nevi_nhm <- 2.5 * \n  (s2_nhm_10m[[\"NIR\"]] - s2_nhm_10m[[\"R\"]]) / \n  (s2_nhm_10m[[\"NIR\"]] + \n    6 * s2_nhm_10m[[\"R\"]] - \n    7.5 * s2_nhm_10m[[\"B\"]] + 1)\n  \nevi_silwood <- 2.5 * \n  (s2_silwood_10m[[\"NIR\"]] - s2_silwood_10m[[\"R\"]]) / \n  (s2_silwood_10m[[\"NIR\"]] + \n    6 * s2_silwood_10m[[\"R\"]] - \n    7.5 * s2_silwood_10m[[\"B\"]] + 1)\n\n# Rename the single band \nnames(evi_silwood) <- names(evi_nhm) <- \"EVI\"\n\nThere is an issue with the EVI data for the NHM site: there are some anomalous high\nvalues in the satellite data that lead to extreme EVI values. You can see these local\nissues as hotspots if you try plotting these bands (e.g. plot(s2_nhm_10m[[\"NIR\"]])).\nWe can fix that problem by setting extreme values to NA - this is another useful\nmethod for manipulating raster data.\n\n# Remove anomalous EVI values\nevi_nhm[evi_nhm > 1] <- NA\nevi_nhm[evi_nhm < -1] <- NA\n\nNow we can plot the EVI maps.\n\n# Plot the EVI index data\npar(mfrow=c(1, 2))\nplot(evi_silwood)\nplot(evi_nhm)\n\n","type":"content","url":"/gis-practical#evi","position":61},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Sampling from raster datasets"},"type":"lvl2","url":"/gis-practical#sampling-from-raster-datasets","position":62},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Sampling from raster datasets"},"content":"A common need in spatial analysis is to get raster values from locations: for example,\nwhat are the EVI values at the nest box locations, or what are the heights of the sensor\nlocation sites. We can do this using the terra::extract function, which takes a raster\nand a vector dataset and returns the cell values under the vector features.","type":"content","url":"/gis-practical#sampling-from-raster-datasets","position":63},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Point features","lvl2":"Sampling from raster datasets"},"type":"lvl3","url":"/gis-practical#point-features","position":64},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Point features","lvl2":"Sampling from raster datasets"},"content":"With point features this is very easy - you get the values under each point.\n\n# Extract the EVI values under the nest boxes\nnest_box_evi <- extract(evi_silwood, nest_boxes)\nhist(nest_box_evi$EVI)\n\nIt is a little more difficult for the sensors because the heights are in two different\ndatasets, so we need to use extract twice and then combine the results. The\nterra::extract function returns a row with NA if there is no data for a site, so we\ncan merge the data simply by joining the two datasets together and dropping the NA rows.\n\n# Extract the heights at the two sites\nsensor_elevations_silwood <- extract(silwood_dtm, sensor_locations)\nsensor_elevations_nhm <- extract(nhm_dtm, sensor_locations)\n\n# Combine the values from the two rasters and drop to the combined data\nsensor_elevations <- na.omit(rbind(sensor_elevations_silwood, sensor_elevations_nhm))\n\n# Show the data\nhead(sensor_elevations)\n\n","type":"content","url":"/gis-practical#point-features","position":65},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Line features","lvl2":"Sampling from raster datasets"},"type":"lvl3","url":"/gis-practical#line-features","position":66},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Line features","lvl2":"Sampling from raster datasets"},"content":"You might also want to know what the values under a line feature are: either because you\nwant a distribution of those values, or possible because you want a sequence of values\nalong the feature. These two things are different - we’ll look at them using the\nSilmas walk/run route.\n\nIf we just use extract with the line features, then terra::extract returns the values\nof all of the cells that the line touches. The values are not in sequence along the line\nfeature - they are just all the values it touches. We can see the cells that are being\nselected by rasterising the route.\n\n# Extract the heights under the Silmas route\nsilmas_heights <- extract(silwood_dtm, silmas_route, xy=TRUE)\n\npar(mfrow=c(1,2))\n# Convert the Silmas route into a raster to show the sampled cells\nsilmas_route_raster <- rasterize(silmas_route, silwood_dtm)\nplot(silwood_dtm, col=grey.colors(20))\nplot(silmas_route_raster, col=\"red\", add=TRUE, legend=FALSE)\n\n# Show the height distribution of all the cells that the route crosses\nhist(silmas_heights$Elevation, xlab = \"Elevation of Silmas route cells (m)\", main=\"\")\n\nIf you want to get a sequence of values along a linear feature then you need to\nextract the values in order. To do this, you need to convert the linear feature to\npoints by casting it to the simpler feature type. This gives us a warning that\nbasically just says that it is assigning the attributes for the whole linear feature to\neach and every point, and that might not be sensible. If the points are very spaced out,\nyou can use sf::st_segmentize to interpolate more points along the feature.\n\nsilmas_points <- st_cast(silmas_route, \"POINT\")\n\nWe can now use terra::extract on the points to get the heights in sequence. We can\nalso use Pythagoras’ theorem to get the cumulative distance along the route from the\ncoordinates.\n\n# Get the height of each GPS point along the route\nsilmas_heights <- extract(silwood_dtm, silmas_points)\n\n# Get the coordinates of the points and use Pythagoras to ge the distance.\ncoords <- as.data.frame(st_coordinates(silmas_points))\ncoords$distance <- c(0, sqrt(diff(coords$X)**2 + diff(coords$Y)**2))\ncoords$total_distance <- cumsum(coords$distance)\ncoords$height <-silmas_heights$Elevation\n\n# Plot the height profile of the Silmas walk\nplot(height~ total_distance, data=coords, type=\"l\")\n\n","type":"content","url":"/gis-practical#line-features","position":67},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Polygon features","lvl2":"Sampling from raster datasets"},"type":"lvl3","url":"/gis-practical#polygon-features","position":68},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Polygon features","lvl2":"Sampling from raster datasets"},"content":"It is extremely common to want to get a distribution or summary statistic of raster\nvalues within a polygon feature: for example, what is the average elevation within 50\nmetres of each of the sensor locations? The first thing to do is to get polygons that\nform a 50m radius circle around each sensor locations using the sf::st_buffer\nfunction.\n\n# Get 50m radius polygons around the sensor points\nsensor_locations_50 <- st_buffer(sensor_locations, 50)\n\nYou can use sf::st_buffer with any features to get polygons extending out from the\nfeature, and you can in fact use negative distances to get polygons within existing\npolygons. We can then use the polygon features with terra::extract to get a data frame\nof the values from the digital elevation map associated with each sensor location. We\nagain need to join the results from the two sites together and drop any NA rows.\n\n# Get the values within the 50m buffer for each sensor location, \nsilwood_sensor_heights <- extract(silwood_dtm, sensor_locations_50)\nnhm_sensor_heights <- extract(nhm_dtm, sensor_locations_50)\nsensor_heights <- na.omit(rbind(silwood_sensor_heights, nhm_sensor_heights))\n\n# How many values per site?\ntable(sensor_heights$ID)\n\n# Height variation between sensors\nboxplot(Elevation ~ ID, data= sensor_heights)\n\nWe can also extract data from categorical rasters:\n\n# Get the values within the 50m buffer for each sensor location, \nsilwood_sensor_LCM <- extract(silwood_LCM, sensor_locations_50)\nnhm_sensor_LCM <- extract(nhm_LCM, sensor_locations_50)\nsensor_LCM <- na.omit(rbind(silwood_sensor_LCM, nhm_sensor_LCM))\n\n# Land cover class counts within 50m of each sensor.\nxtabs(~ LandCover + ID, data= sensor_LCM, drop.unused.levels=TRUE)\n\nSide note\n\nAs a sidenote, the standard way this works is to use the terra::rasterize function to\nfind all of the raster cells where the cell centre falls within a polygon feature, but\nyou can optionally choose to also include any cells that the cell boundary touches,\nusing the touches=TRUE setting. The plot below shows the two alternatives for a single\nsensor polygon.\n\n# Create an extent around a single sensor\nzoom_to_site_one <- ext(c(493835,  493955, 169200, 169330))\n\n# Rasterize using the two methods\ncell_touches_false <- rasterize(sensor_locations_50[1,], silwood_dtm)\ncell_touches_true <- rasterize(sensor_locations_50[1,], silwood_dtm, touches=TRUE)\n\n# Plot side by side as DTM overplotted with rasterized polygon and polygon border\npar(mfrow=c(1,2))\n\nplot(\n  silwood_dtm, ext=zoom_to_site_one, legend=FALSE, \n  col=gray.colors(20), main=\"touches=FALSE\"\n)\nplot(cell_touches_false, add=TRUE, legend=FALSE, col=\"firebrick\")\nplot(st_geometry(sensor_locations_50[1,]), col=NA, add=TRUE)\n\nplot(\n  silwood_dtm, ext=zoom_to_site_one, legend=FALSE, \n  col=gray.colors(20), main=\"touches=TRUE\"\n)\nplot(cell_touches_true, add=TRUE, legend=FALSE, col=\"firebrick\")\nplot(st_geometry(sensor_locations_50[1,]), col=NA, add=TRUE)\n\n","type":"content","url":"/gis-practical#polygon-features","position":69},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Zonal statistics","lvl2":"Sampling from raster datasets"},"type":"lvl3","url":"/gis-practical#zonal-statistics","position":70},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Zonal statistics","lvl2":"Sampling from raster datasets"},"content":"You can also sample from a raster dataset using another raster dataset. In practice,\nthis is what is happening when you extract data from a vector feature - the different\nfeatures get converted into raster layers in order to identify which cells to extract.\nBut if you already have a categorical raster, you can simply use the terra::zonal\nfunction to extract the values under each raster cateogory.\n\n# Extract the EVI values for each LCM raster cell\nevi_by_LCM <- zonal(evi_silwood, silwood_LCM, wide=FALSE)\nhead(evi_by_LCM)\n\nWe can then visualise the range of EVI values by land cover class:\n\npar(mar = c(4,12,1,1))\nplot(EVI ~ as.factor(LandCover), data=evi_by_LCM, horizontal=TRUE, las=1, xlab=\"\")\n\n","type":"content","url":"/gis-practical#zonal-statistics","position":71},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Image classification"},"type":"lvl2","url":"/gis-practical#image-classification","position":72},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Image classification"},"content":"We already have the CEH Land Cover map, but we may be able to get a better local model\nof land cover by classifying the Sentinel 2 data. Image classification is the process of\ntaking spectral data from an image and identifying particular spectral signatures\n(combinations of values in the different bands) with a land cover category. You can\nclassify simple RGB images, but it is often better to use data with more spectral bands:\nas we saw with the false colour infrared image, some bands are great at picking out\nparticular features.","type":"content","url":"/gis-practical#image-classification","position":73},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Unsupervised classification","lvl2":"Image classification"},"type":"lvl3","url":"/gis-practical#unsupervised-classification","position":74},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Unsupervised classification","lvl2":"Image classification"},"content":"Unsupervised classification tries to extract clusters of spectral signatures from the\ndata. There are many approaches, but the basic aim of the algorithms is to try and find\nsets of points in the image that have similar spectral signatures.\n\nHere we will use the base R stats::kmeans function to carry out k-means clustering on\nthe data. The k of the k-means is the number of clusters we want to identify, and here\nwe are letting the algorithm pick 10 random starting points from with the image spectra\nand then iterating to try and find stable sets of clusters. It then repeats that process\nwith different starting choices and returns a classification across all of the runs.\n\n# We need to convert the raster data into a data frame giving the \n# spectral signature of each cell\nvalues <- as.data.frame(s2_silwood_10m)\nhead(values)\n\n# Now we can run the clustering\nn_cats <- 6\ns2_kmeans <- kmeans(\n  values, centers=n_cats, iter.max = 500, nstart = 5, algorithm=\"Lloyd\"\n)\n\n# We can now take the cluster attribute from the output and put those values\n# back into a 10m resolution raster\ns2_kmeans_map <- rast(s2_silwood_10m, nlyr=1)\nvalues(s2_kmeans_map) <- s2_kmeans$cluster\n\nNow that we have the map, we can add labels and category names, as we did above for the\nCEH dataset.\n\nlabels <- data.frame(ID=1:n_cats, category=paste0(\"Category_\", 1:n_cats))\n#colours <- data.frame(ID=1:n_cats, colours=hcl.colors(n_cats, \"Dark 2\"))\n\ncolours <- data.frame(ID=1:n_cats, colours=carto_pal(n_cats, \"Safe\"))\n\nlevels(s2_kmeans_map) <- labels\ncoltab(s2_kmeans_map) <- colours\n\nplot(s2_kmeans_map)\n\n","type":"content","url":"/gis-practical#unsupervised-classification","position":75},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Supervised classification","lvl2":"Image classification"},"type":"lvl3","url":"/gis-practical#supervised-classification","position":76},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Supervised classification","lvl2":"Image classification"},"content":"The classes from an unsupervised classification are a purely statistical construction:\nthey often do identify meaningful land cover types, but they need to be interpreted and\nit is common to re-run the process with different numbers of classes, or to merge\nclasses that identify very similar regions.\n\nThe alternative of supervised classification avoids that by starting with a training\ndataset of sites with known categories. The spectral signatures of those sites can then\nbe used to assign other sites to classes based on their similarity to the training data.\nThis does mean that you need to put together a training dataset in one of two ways:\n\nphysically exploring the location with a GPS and assigning classes based on field data\n(“ground truthing”), or\n\nselecting points from the imagery that visually belong to a particular class\n(“digitization”).\n\nHere we use a training set drawn from inspecting the imagery, saved as a set of X and Y\npoint coordinates and the land cover category at that point. There are multiple sites\nfor each class, giving a distribution of signatures associated with each class.\n\n# Load the classification data and convert it to an SF point dataset\ntraining_sites <- read.csv(\"../data/SpatialMethods/S2_classification_data.csv\")\ntraining_sites <- st_as_sf(training_sites, coords=c(\"x\",\"y\"), crs=\"EPSG:27700\")\n\n# Plot the data over the top of an aerial image. This is a bit of a hack\n# as it plots the vector data first to get the legend, then plots the aerial\n# photo over the top and then the training sites _again_.\nplot(training_sites, reset=FALSE)\nplotRGB(silwood_aerial, add=TRUE)\nplot(training_sites, add=TRUE)\n\n# Show a table of the number of training sites for each category.\ntable(training_sites$category)\n\nWe can then extract the spectral signatures at each of those sites to give a spectral\ntraining dataset to use in classification.\n\n# Extract a data frame of band values at each training site and add the\n# category field to the dataset.\ntraining_spectra <- extract(s2_silwood_10m, training_sites, ID=FALSE)\ntraining_spectra$category <- training_sites$category\n\nWe will use a regression tree model using the rpart::rpart function to assign spectral\nsignatures to classes. A regression tree finds critical values in the different bands\nthat separate different classes and provides a simple decision tree based on the\ntraining data that can then be used to classify the whole image.\n\n# Fit a regression tree of the land cover category as a function of the bands\ns2_class_model <- rpart(\n  category ~  B + G + R + NIR + RE5 + RE6 + RE7 + NNIR + SWIR1 + SWIR2,\n  data = training_spectra, method = 'class', minsplit = 5\n)\n\n# Show the regression tree.\nprint(s2_class_model)\n\nThe model can then be used to predict values for all of the pixels. The resulting\nraster has one layer for each land cover type that gives the probability that the pixel\nis in that class.\n\n# Generate the predictions for the whole map\ns2_class_probability <- predict(s2_silwood_10m, s2_class_model)\n\n# Plot 3 of the probability layers\nplot(s2_class_probability[[1:3]], nc=3)\n\nWe can convert it into a land cover map by assigning each pixel to the class where it\nhas the highest probability.\n\n# Find the layer with the highest probability. The index of that code gives the \n# associated land  cover type\ns2_class_map <- which.max(s2_class_probability)\n\n# Assign level labels to the index codes.\nlevels(s2_class_map) <- data.frame(id=1:7, class=names(s2_class_probability))\nplot(s2_class_map, col=carto_pal(7, \"Safe\"))\n\nIt is good practice to partition your training dataset to then test the accuracy of the\nclassification - can your model successfully predict the classes of the data retained in\nthe test partition. There are a lot of approaches to this (k-fold cross validation is a\ncommon one) but these are outside the scope of this practical.\n\nGenerating training data\n\nDigitizing training data is one of those tasks where it may be easier to use a dedicated\nGIS program like GIS. This is mostly because it is easier to zoom in on an image to\nprecisely place the training locations.\n\nHowever, you can use R to create training datasets. The code below defines a function\nthat can be used to generate a training data frame and then extend it with training data\nfor different classes.\n\npick_training_sites <- function(category, df = NULL) {\n    #' Function to add training data locations by clicking on a displayed map.\n    #' \n    #' The function returns a data frame with the X and Y coordinates of the clicked\n    #' points and a category field giving the `category` label for with the points.\n    #' Press 'Escape' to finish collecting points and return a dataframe of coordinates.\n    #' The returned dataframe for one category can be passed back into the `df`\n    #' argument to append sites for a new category to the existing data. \n\n    # Pick the points from a plotted GIS map\n    xy <- draw(\"points\", pch=4)\n    # Convert the selected coordinates to a dataframe and add the category label\n    new_data <- as.data.frame(crds(xy))\n    new_data$category <- category\n\n    # Return the new_data appended to any existing data\n    return(rbind(df, new_data))\n}\n\n# Plot the image\nplotRGB(silwood_aerial)\n\n# Build up the training set by clicking on the image and then pressing\n# \"escape\" to finish defining one class and to move onto the next category\ndf <- pick_training_sites(\"Urban\")\ndf <- pick_training_sites(\"Grassland\", df=df)\ndf <- pick_training_sites(\"Water\", df=df)\ndf <- pick_training_sites(\"Silwood Lake\", df=df)\ndf <- pick_training_sites(\"Bare Ground\", df=df)\ndf <- pick_training_sites(\"Woodland\", df=df)\ndf <- pick_training_sites(\"Road\", df=df)\n\n# Export the data\nwrite.csv(df, \"../data/SpatialMethods/S2_classification_data.csv\", row.names=FALSE)","type":"content","url":"/gis-practical#supervised-classification","position":77},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Saving GIS files"},"type":"lvl2","url":"/gis-practical#saving-gis-files","position":78},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl2":"Saving GIS files"},"content":"\n\n# Remove any existing data output folder rather than have to stick a load of \n# overwrite=TRUE arguments in the student facing text.\nif (dir.exists(\"spatial_method_practical_outputs\")) {\n  unlink(\"spatial_method_practical_outputs\", recursive=TRUE)\n}\n\nWe have created a lot of new dataset during this practical, which we should save for\nfuture use. The first thing to do is create a new directory to save the data files in:\n\n# Create an output directory\ndir.create(\"spatial_method_practical_outputs\")\nsetwd(\"spatial_method_practical_outputs\")\n\n","type":"content","url":"/gis-practical#saving-gis-files","position":79},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Saving raster data","lvl2":"Saving GIS files"},"type":"lvl3","url":"/gis-practical#saving-raster-data","position":80},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Saving raster data","lvl2":"Saving GIS files"},"content":"We can write raster data out using the terra::writeRaster function. This\nfunction writes all the bands in the dataset out to a single file. The function uses the\nfile suffix of the file name you provide to set the output format: there are lots of\nformats, but GeoTIFF is widely used and a good general choice.\n\n# Create an output directory\ndir.create(\"spatial_method_practical_outputs\")\nsetwd(\"spatial_method_practical_outputs\")\n\n# Save the NDVI and EVI data\nwriteRaster(ndvi_silwood, \"NDVI_Silwood.tiff\")\nwriteRaster(ndvi_nhm, \"NDVI_NHM.tiff\")\n\nwriteRaster(evi_silwood, \"EVI_Silwood.tiff\")\nwriteRaster(evi_nhm, \"EVI_NHM.tiff\")\n\n# Save the multiband Sentinel 2 data\nwriteRaster(s2_silwood_10m, \"Sentinel2_Silwood.tiff\")\nwriteRaster(s2_nhm_10m, \"Sentinel2_NHM.tiff\")\n\n","type":"content","url":"/gis-practical#saving-raster-data","position":81},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Saving vector data","lvl2":"Saving GIS files"},"type":"lvl3","url":"/gis-practical#saving-vector-data","position":82},{"hierarchy":{"lvl1":"Spatial methods in Ecological and Evolutionary Data Science","lvl3":"Saving vector data","lvl2":"Saving GIS files"},"content":"The sf_st::write function is used to write vector data to file. Again, the file format\nis inferred from the output file name. This sf_st::write function is slightly more\ncomplex because file formats work in slightly different ways. The function has three\nmain arguments:\n\nobj: The sf object you want to write to a file.\n\ndsn: The data source name that usually gives a filename that the data will be\nwritten to.\n\nlayer: A layer name within the data source that the data will be saved under. Not\nall formats support multiple layers (e.g. shapefiles), so you do not always need to\nprovide a layer name.\n\nThere are many, many vector file formats - see the help file on sf::st_drivers() and\nthe output\n\nst_drivers()$name\n\nThe GeoPackage format is generally more convenient because it is a single file and can\nhold multiple layers.  The code below saves the four processed VML subsets to a single\nGeoPackage file.\n\n# Save the VML to GPKG\nst_write(silwood_VML_roads, dsn=\"OS_VML_Silwood_NHM.gpkg\", layer=\"silwood_VML_roads\")\nst_write(nhm_VML_roads, dsn=\"OS_VML_Silwood_NHM.gpkg\", layer=\"nhm_VML_roads\")\nst_write(silwood_VML_water, dsn=\"OS_VML_Silwood_NHM.gpkg\", layer=\"silwood_VML_water\")\nst_write(nhm_VML_water, dsn=\"OS_VML_Silwood_NHM.gpkg\", layer=\"nhm_VML_water\")\n\nAlthough the Shapefile format is more widely known, the inconvience of having multiple\nfiles is high and often leads to problems with incomplete datasets. It also has some odd\nconstraints - as you can see in the output below, there is a limit to the length of\nattribute table field names in shapefiles.\n\n# Save the sensors as shapefile\nst_write(sensor_locations, dsn=\"sensor_locations.shp\")","type":"content","url":"/gis-practical#saving-vector-data","position":83},{"hierarchy":{"lvl1":"Introduction to the practicals"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Introduction to the practicals"},"content":"These pages provide the practical guides for the  Ecological and Evolutionary Data\nScience module for the following masters programmes at Imperial College London: the\nLiving Planet program at the Silwood Park campus and Taxonomy, Biodiversity and\nEvolution MSc and Biosystematics MRes at the Natural History Museum. All of these\npracticals are self-paced: you can work through them at your own speed\nand call out when you need help.\n\nWork in progress\n\nThis site is a work in progress - not all of the practicals in the module have been\nadded to this website\n\nSpatial methods in Ecological and Evolutionary Data Science","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"Three before ‘me’"},"type":"lvl2","url":"/#three-before-me","position":2},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"Three before ‘me’"},"content":"There will be a team of demonstrators to help you when you get stuck but please do\nremember that helping yourself is actually a far better way to learn. We do not want\nyou to struggle but before you reach out to a demonstrator:\n\nAsk yourself what you are trying to do: often stepping back and trying to write out\nan explanation for your problem helps you solve it.\n\nAsk the internet: Sites like \n\nstackoverflow.com are an\ninvaluable resource and you can use tags on stackoverflow (e.g. [R] or [sf])\nto narrow down your search.\n\nAsk each other: it can be really helpful to get together in a short Team meeting\nand crowd source an answer.\n\nIf none of those work then ask us!","type":"content","url":"/#three-before-me","position":3},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"Getting started"},"type":"lvl2","url":"/#getting-started","position":4},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"Getting started"},"content":"You will need to install the required packages and the data required in the\npracticals. There are quite a lot of required packages - they could take a little\nwhile to set up. See \n\npractical requirements page for\ndetails of the R  packages and data you will need.\n\nOnce you have the packages installed, have created a local working directory for the\ndata and are running in R then create a new script file to record and run your\ncode.\n\nWork through the handouts at your own pace.","type":"content","url":"/#getting-started","position":5},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"GIS packages"},"type":"lvl2","url":"/#gis-packages","position":6},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"GIS packages"},"content":"There are loads of R packages that can load, manipulate and plot GIS data and we will be\nusing several in these practical. In the last few years, the R spatial data community\nhas been working on updating most of the core GIS functionality into a few core\npackages, notably sf and terra. We will focus on using these up-to-date central\npackages, but there will be some occasions where we need to use older packages, such as\nsp and raster.","type":"content","url":"/#gis-packages","position":7},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"Tasks"},"type":"lvl2","url":"/#tasks","position":8},{"hierarchy":{"lvl1":"Introduction to the practicals","lvl2":"Tasks"},"content":"Introducing tasks\n\nA lot of these practicals will consist of following provided code to understand how it\nworks but occasionally there will be tasks to test the skills you have been\nlearning. These will start with a task bar like the one above and then have a\ndescription like this one. There will then be a dropdown section like the one below:\nif you get really stuck, you can click on this to show a solution. Do try and figure it\nout for yourself and if you don’t understand something, ask a demonstrator to help.\n\nShow solution\n\nThese dropdowns may contain notes on the solution# And any R code needed to complete the task","type":"content","url":"/#tasks","position":9},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R"},"type":"lvl1","url":"/microclimate-sensor-analysis-easylog","position":0},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R"},"content":"This tutorial is designed for ecologists and environmental scientists with basic R\nskills. You will learn how to analyze microclimate data collected with an EasyLog USB\ndatalogger, focusing on loading, cleaning, and exploring, environmental time series\ndata.\n\nBy the end of this tutorial, you will be able to:\n\nLoad and combine multiple sensor CSV files and habitat classification data from Excel files\n\nClean your dataset and check for data quality issues\n\nIdentify and flag potential outliers using different methods\n\nVisualize microclimate trends over time and across sites\n\nPerform basic statistical summaries\n\nFit ANOVA to explore ecological relationships\n\nExport cleaned data for further analysis\n\nThe skills and methods you learn here apply broadly to other environmental\ndatasets.","type":"content","url":"/microclimate-sensor-analysis-easylog","position":1},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Load required libraries"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#load-required-libraries","position":2},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Load required libraries"},"content":"You will use several R packages that simplify data manipulation, date handling,\nand plotting:\n\nlibrary(openxlsx2)   # for opening excel files\nlibrary(ggplot2)\nlibrary(dplyr)\n# library(tidyverse)   # for data manipulation and plotting\nlibrary(janitor)     # for cleaning column names and general tidying\nlibrary(patchwork)   # for combining plots\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#load-required-libraries","position":3},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Set up file paths"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#set-up-file-paths","position":4},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Set up file paths"},"content":"In this practical, we expect to find the sensor data and habitat classification data in\nthe directories described in the \n\npractical requirements\nnotes.\n\nMore generally, storing file paths in variables makes your code easier to update and\nmaintain. If you move your data later, you only need to change the code in one place.\n\n# Define the full paths to the folder containing your sensor data and to the \n# metadata file \nsensor_data_folder <- \"../data/Microclimate/2025\"\nsensor_metadata_file <- \"../data/SensorSites/2025/sensor_sites_2025.csv\"\n\n# Get the paths to all of the CSV files containing climate data from this year. This\n# command searches all of the folders within the sensor data folder for *.txt files.\nmicroclimate_files <- dir(\n  path=sensor_data_folder, pattern=\"*.txt\", \n  recursive = TRUE, full.names = TRUE\n)\n\n# Check what files we found\nprint(microclimate_files)\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#set-up-file-paths","position":5},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Read sensor data"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#read-sensor-data","position":6},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Read sensor data"},"content":"Sensor data often contain inconsistencies such as mixed date formats or data types,\nwhich can cause issues during analysis. The format of the output files from the EasyLog\nsensors is also odd - there is the serial number field that only uses the first row.\nHowever, the main data is always in the first five columns. We can use the code below to\ncompile the data across files into a single data frame.\n\n# Create an object name to collect combined data\nall_data <- NULL\n\nfor (each_file in microclimate_files) {\n\n    # Load this file, handling Windows file encoding of characters\n    data <- read.csv(each_file, encoding = \"latin1\")\n    \n    # Extract the name of the first column, which is the sensor ID\n    sensor_id <- names(data)[1]\n\n    # Reduce to the first five columns and standardise the field names\n    data <- subset(data, select=1:5)\n    names(data) <- c(\n      \"observation_id\", \"datetime\", \"temperature\", \"humidity\", \"dewpoint\"\n    )\n    \n    # Record the sensor_id\n    data$sensor_id <- sensor_id\n\n    # Add the data on to the combined data\n    all_data <- rbind(all_data, data)\n}\n\n# Convert the time data and sensor id\nall_data$datetime <- as.POSIXct(all_data$datetime)\nall_data$sensor_id <- factor(all_data$sensor_id)\n\nWhat just happened?\n\nIt is quite common to want to join a set of identical files into a single data frame.\nThe base::rbind function is used to combine two data frames, but how do you get this\nstarted: do you load one file first and then loop the rest? The trick is that\nrbind(NULL, my_data_frame) just gives you back my_data_frame, so we can use it to\nstart the loop over all the files.\n\nWe should now be able to preview the data\n\nprint(head(all_data))\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#read-sensor-data","position":7},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"First inspection of the data"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#first-inspection-of-the-data","position":8},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"First inspection of the data"},"content":"Before doing any statistics, always look at your raw data. An easy way to do this is\na basic boxplot:\n\nggplot(all_data, aes(x = sensor_id, y = temperature)) +\n  geom_boxplot() +\n  labs(\n    title = \"Temperature distribution per sensor\",\n    x = \"Sensor ID\",\n    y = \"Temperature (°C)\"\n  )\n\nIf you see values far outside the main cluster, they might be outliers or errors.\nHowever, remember: not all extreme values are mistakes, a sudden heat spike could be\nreal. Always think carefully before you remove any points from your data set.","type":"content","url":"/microclimate-sensor-analysis-easylog#first-inspection-of-the-data","position":9},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"Quick detour: Comparison to station data","lvl2":"First inspection of the data"},"type":"lvl3","url":"/microclimate-sensor-analysis-easylog#quick-detour-comparison-to-station-data","position":10},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"Quick detour: Comparison to station data","lvl2":"First inspection of the data"},"content":"Go online to explore historic weather data:\n\nUK Met office WOW\n\nTime and Date historic weather\n\nLook for temperature time series covering your measurement period. Compare:\n\nAre the daily patterns similar?\n\nIs the temperature range realistic for the time of year?\n\nWere any extreme values recorded?\n\nIf you find differences between your data and the station observations data,\nwhat could be possible reasons?","type":"content","url":"/microclimate-sensor-analysis-easylog#quick-detour-comparison-to-station-data","position":11},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Identifying outliers"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#identifying-outliers","position":12},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Identifying outliers"},"content":"There are several ways to identify outliers. The table below summarizes three\ncommon methods with their pros and cons.\n\nYou already did the visual inspection;\nZ-score and Interquartile Range (IQR) method are described in more detail below.\n\nDo you expect to get the same outliers with different methods?\n\nSensor specific outliers\n\nIt is appropriate to calculate outliers for each sensor individually\nbecause each sensor can have its own baseline, bias, and range of variation.\n\nMethod\n\nHow It Works\n\nPros\n\nCons\n\nVisual\n\nUse boxplots or scatterplots to spot unusual points visually.\n\nQuick, intuitive, and easy to spot obvious anomalies.\n\nNot systematic; subjective; may miss subtle outliers.\n\nZ-score\n\nCalculate how many standard deviations a value is from the mean.\n\nFast to compute; effective for bell-shaped (normal) data.\n\nMisleading for skewed data or when extreme values distort mean and SD.\n\nInter-quartile range (IQR)\n\nFlags points outside 1.5×IQR below Q1 or above Q3 percentiles.\n\nRobust to skewed data; less influenced by extreme values.\n\nMay label valid extreme values as outliers, especially with small sample sizes.","type":"content","url":"/microclimate-sensor-analysis-easylog#identifying-outliers","position":13},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"Z-score method for outlier detection","lvl2":"Identifying outliers"},"type":"lvl3","url":"/microclimate-sensor-analysis-easylog#z-score-method-for-outlier-detection","position":14},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"Z-score method for outlier detection","lvl2":"Identifying outliers"},"content":"The Z-score measures how far each value is from the mean, in units of standard\ndeviations:Z = \\frac{\\text{value} - \\text{mean}}{\\text{standard deviation}}\n\nA Z-score of 0 = exactly the mean.\n\nA Z-score of +2 = two standard deviations above the mean.\n\nA Z-score of –3 = three standard deviations below the mean.\n\nFor normally distributed data, 99.7% of values lie within ±3 standard deviations.\nValues beyond this range are flagged as potential outliers.\n\nall_data_Z <- all_data %>%\n  # Compute Z-score per sensor_id\n  group_by(sensor_id) %>%\n  mutate(\n    temperature_Z = (\n      (temperature - mean(temperature, na.rm = TRUE))\n      / sd(temperature, na.rm = TRUE)\n    ),\n    temp_outlier_Z = abs(temperature_Z) > 3\n  ) %>%\n  ungroup()\n\n# Check what that added\nprint(head(all_data_Z))\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#z-score-method-for-outlier-detection","position":15},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"Interquartile Range (IQR) Method for Outlier Detection","lvl2":"Identifying outliers"},"type":"lvl3","url":"/microclimate-sensor-analysis-easylog#interquartile-range-iqr-method-for-outlier-detection","position":16},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"Interquartile Range (IQR) Method for Outlier Detection","lvl2":"Identifying outliers"},"content":"The IQR method focuses on the spread of the middle 50% of the data.\nIt calculates the difference between the 75th percentile (Q3) and the\n5th percentile (Q1), called the interquartile range (IQR). Values falling below\n( Q1 - 1.5 \\times IQR ) or above ( Q3 + 1.5 \\times IQR ) are considered\npotential outliers.\n\n# Use the IQR method to flag temperature outliers per sensor\nall_data_IQR <- all_data %>%\n  group_by(sensor_id) %>%\n  mutate(\n    # Temperature IQR\n    temp_Q1 = quantile(temperature, 0.25, na.rm = TRUE),\n    temp_Q3 = quantile(temperature, 0.75, na.rm = TRUE),\n    temp_IQR = temp_Q3 - temp_Q1,\n    temp_outlier_IQR = if_else(\n      temperature < (temp_Q1 - 1.5 * temp_IQR) | temperature > (temp_Q3 + 1.5 * temp_IQR),\n      TRUE, FALSE, missing = FALSE\n    ),\n  ) %>%\n  ungroup()\n\n# Check what that added\nprint(head(all_data_IQR))\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#interquartile-range-iqr-method-for-outlier-detection","position":17},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Visualize temperature over time with outliers highlighted"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#visualize-temperature-over-time-with-outliers-highlighted","position":18},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Visualize temperature over time with outliers highlighted"},"content":"\n\noptions(repr.plot.width=12, repr.plot.height=10)\n\n# Plot using IQR outlier flags\np1 <- ggplot(\n  all_data_IQR,\n  aes(x = datetime, y = temperature, color = temp_outlier_IQR, group = sensor_id)\n) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~sensor_id) +\n  scale_color_manual(values = c(\"black\", \"red\")) +\n  labs(\n    title = \"Temperature over Time (IQR Outliers)\",\n    x = \"Datetime\",\n    y = \"Temperature (°C)\",\n    color = \"Outlier\"\n  ) +\n  theme_minimal()\n\n# Plot using Z-score outlier flags\np2 <- ggplot(\n  all_data_Z,\n  aes(x = datetime, y = temperature, color = temp_outlier_Z, group = sensor_id)\n) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~sensor_id) +\n  scale_color_manual(values = c(\"black\", \"blue\")) +\n  labs(\n    title = \"Temperature over Time (Z-score Outliers)\",\n    x = \"Datetime\",\n    y = \"Temperature (°C)\",\n    color = \"Outlier\"\n  ) +\n  theme_minimal()\n\n# Combine plots side-by-side\np1 + p2 + plot_layout(ncol = 1)\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#visualize-temperature-over-time-with-outliers-highlighted","position":19},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Read and add sensor location"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#read-and-add-sensor-location","position":20},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Read and add sensor location"},"content":"You will have recorded metadata such as habitat type, location coordinates, or\nnotes about the sensor placement during your field experiment in an Excel\nspreadsheet. The rest of the module will add extra data on the differences between the\nsensor location sites, but for now we can simply look to see if there are any\ndifferences between the NHM and Silwood by using the longitude of the locations.\n\n# Read meta data\nmetadata <- read.csv(sensor_metadata_file)\n\n# Get the site location using longitude\nmetadata$site <- ifelse(metadata$long_Sensor_location > -0.5, \"NHM\", \"Silwood\")\n\n# Drop down to two required fields and change Sensor ID from DL-xxx to DL.xxx to match \n# EpiCollect 5 metadata file\nhabitat_classification <- metadata[,c(\"Logger_SerialNumber\", \"site\")]\nnames(habitat_classification) <- c(\"sensor_id\", \"site\")\nhabitat_classification$sensor_id <- sub(\"-\", \".\", habitat_classification$sensor_id)\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#read-and-add-sensor-location","position":21},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Summarize maximum temperature per sensor"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#summarize-maximum-temperature-per-sensor","position":22},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Summarize maximum temperature per sensor"},"content":"The following analysis focuses on the IQR data set; try the same\nsteps with the Z-score or other alternative methods in your own time.\n\n# Remove outliers and NAs before summarising\nsummary_data <- all_data_IQR %>%\n  filter(!temp_outlier_IQR, !is.na(temperature)) %>%\n  group_by(sensor_id) %>%\n  summarize(max_temperature = max(temperature), .groups = \"drop\") %>%\n  left_join(habitat_classification, by = \"sensor_id\") # add metadata\n\n# Display summary table\nprint(summary_data)\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#summarize-maximum-temperature-per-sensor","position":23},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Fit ANOVA: max temperature ~ location"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#fit-anova-max-temperature-location","position":24},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Fit ANOVA: max temperature ~ location"},"content":"ANOVA (Analysis of Variance) is a statistical method used to test whether the\nmeans of a continuous variable differ significantly across two or more groups.\n\nTest whether the max temperature is predicted by location. What do you expect?\n\n# Fit ANOVA\nanova_model <- lm(max_temperature ~ site, data = summary_data)\nsummary(anova_model) # View ANOVA table\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#fit-anova-max-temperature-location","position":25},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Boxplot maximum temperature - habitat type relationship"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#boxplot-maximum-temperature-habitat-type-relationship","position":26},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Boxplot maximum temperature - habitat type relationship"},"content":"\n\nggplot(summary_data, aes(x = site, y = max_temperature)) +\n  geom_boxplot(fill = \"lightblue\", alpha = 0.6) +\n  geom_jitter(width = 0.1, size = 2, alpha = 0.7) +\n  labs(\n    title = \"Maximum Temperature by Habitat Type\",\n    x = \"Habitat Type\",\n    y = \"Max Temperature (°C)\"\n  ) +\n  theme_minimal()\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#boxplot-maximum-temperature-habitat-type-relationship","position":27},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Export new data set"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#export-new-data-set","position":28},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Export new data set"},"content":"This is a good moment to export the combined data set from all sensors, including\ninformation on IQR and outliers.\n\nwrite.csv(all_data_IQR, file.path(sensor_data_folder, \"all_sensor_data_2025.csv\"))\n\n","type":"content","url":"/microclimate-sensor-analysis-easylog#export-new-data-set","position":29},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Optional extensions"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#optional-extensions","position":30},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Optional extensions"},"content":"Now that you are familiar with the dataset, go explore other variables,\nstatistics, or relationships, for example:\n\nPlotting humidity vs. habitat type\n\nLooking at the diurnal cycle (average daily pattern)\n\nComparing spatial variation between sensors","type":"content","url":"/microclimate-sensor-analysis-easylog#optional-extensions","position":31},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Reflection Tasks"},"type":"lvl2","url":"/microclimate-sensor-analysis-easylog#reflection-tasks","position":32},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl2":"Reflection Tasks"},"content":"","type":"content","url":"/microclimate-sensor-analysis-easylog#reflection-tasks","position":33},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"1. Descriptive statistics paragraph","lvl2":"Reflection Tasks"},"type":"lvl3","url":"/microclimate-sensor-analysis-easylog#id-1-descriptive-statistics-paragraph","position":34},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"1. Descriptive statistics paragraph","lvl2":"Reflection Tasks"},"content":"Write a short summary of:\n\nYour dataset (number of sensors, time range, variables measured)\n\nAny unusual patterns or outliers\n\nHow your measurements compare with official weather station data","type":"content","url":"/microclimate-sensor-analysis-easylog#id-1-descriptive-statistics-paragraph","position":35},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"2. Interpretation of modelling results","lvl2":"Reflection Tasks"},"type":"lvl3","url":"/microclimate-sensor-analysis-easylog#id-2-interpretation-of-modelling-results","position":36},{"hierarchy":{"lvl1":"Microclimate sensor data analysis in R","lvl3":"2. Interpretation of modelling results","lvl2":"Reflection Tasks"},"content":"In ~300 words, explain:\n\nWhat your ANOVA shows\n\nWhether this result supports your hypothesis\n\nKey takeaway\n\nData cleaning and exploratory analysis are not just “pre-work”, they are\nessential steps in understanding your data set, spotting problems, and making\nsure your conclusions are valid.","type":"content","url":"/microclimate-sensor-analysis-easylog#id-2-interpretation-of-modelling-results","position":37},{"hierarchy":{"lvl1":"Required packages and data"},"type":"lvl1","url":"/practical-requirements","position":0},{"hierarchy":{"lvl1":"Required packages and data"},"content":"If you are running these practicals on your own laptop then you will need to install\nquite a few packages to get the code to run. The following sections give the core\npackages required and then practical specific packages.","type":"content","url":"/practical-requirements","position":1},{"hierarchy":{"lvl1":"Required packages and data","lvl2":"Practical directory setup"},"type":"lvl2","url":"/practical-requirements#practical-directory-setup","position":2},{"hierarchy":{"lvl1":"Required packages and data","lvl2":"Practical directory setup"},"content":"Because these practicals link up and share data, it is best to set up a shared data\nfolder and then create folders for each practical:\n\nCreate a directory for the practicals (e.g. eco_evo_data_science).\n\nWithin that directory, create the following directories:\n\ndata: this will contains subfolders containing the different types of sensor\ndata and other datasets for use in the module.\n\nspatial_methods: This directory will be used for the \n\nSpatial\nMethods practical\n\nmicroclimate: This directory will be used for the\n\n\nMicroclimate practical","type":"content","url":"/practical-requirements#practical-directory-setup","position":3},{"hierarchy":{"lvl1":"Required packages and data","lvl2":"Spatial methods practical"},"type":"lvl2","url":"/practical-requirements#spatial-methods-practical","position":4},{"hierarchy":{"lvl1":"Required packages and data","lvl2":"Spatial methods practical"},"content":"You will need to install the following packages:# Core GIS package\ninstall.packages('terra')\ninstall.packages('sf')\n\nYou will also need to download the practical data bundle:\n\nDownload the SpatialMethods directory in the \n\nBox site for the\nmodule into the data\ndirectory.\n\nDownload the SensorSites directory in the \n\nBox site for the\nmodule into the data\ndirectory.","type":"content","url":"/practical-requirements#spatial-methods-practical","position":5},{"hierarchy":{"lvl1":"Required packages and data","lvl2":"Microclimate practical"},"type":"lvl2","url":"/practical-requirements#microclimate-practical","position":6},{"hierarchy":{"lvl1":"Required packages and data","lvl2":"Microclimate practical"},"content":"You will need to install the following packages:install.packages(openxlsx2)   # for opening excel files\ninstall.packages(tidyverse)   # for data manipulation and plotting\ninstall.packages(janitor)     # for cleaning column names and general tidying\ninstall.packages(patchwork) \n\nYou will also need to download the practical data bundle:\n\nDownload the Microclimate directory in the \n\nBox site for the\nmodule into the data\ndirectory.\n\nDownload the SensorSites directory in the \n\nBox site for the\nmodule into the data\ndirectory.","type":"content","url":"/practical-requirements#microclimate-practical","position":7}]}